{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "from tensorflow import estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Clean_Data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feature=[f for f in data.columns if data[f].dtype=='object']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cat_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['WheelTypeID',\n",
       " 'MMRAcquisitionAuctionAveragePrice',\n",
       " 'MMRAcquisitionAuctionCleanPrice',\n",
       " 'MMRAcquisitionRetailAveragePrice',\n",
       " 'MMRAcquisitonRetailCleanPrice',\n",
       " 'MMRCurrentAuctionAveragePrice',\n",
       " 'MMRCurrentAuctionCleanPrice',\n",
       " 'MMRCurrentRetailAveragePrice',\n",
       " 'MMRCurrentRetailCleanPrice',\n",
       " 'VehBCost']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "continous_feature=[f for f in data.columns if data[f].dtype=='float64']\n",
    "continous_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IsBadBuy',\n",
       " 'VehYear',\n",
       " 'VehicleAge',\n",
       " 'VehOdo',\n",
       " 'BYRNO',\n",
       " 'IsOnlineSale',\n",
       " 'WarrantyCost']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_feature=[f for f in data.columns if data[f].dtype=='int64']\n",
    "integer_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x=data.drop('IsBadBuy', axis=1)\n",
    "data_y=data['IsBadBuy']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_scale=continous_feature[1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_scale.append(\"VehOdo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_to_scale.append(\"WarrantyCost\")\n",
    "len(feature_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "#Scaling data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler=MinMaxScaler()\n",
    "scaler.fit(data[feature_to_scale])\n",
    "scaled_data=scaler.transform(data[feature_to_scale])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data_Min_Max=pd.DataFrame(data=scaled_data,columns=feature_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[feature_to_scale]=scaled_data_Min_Max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to excel\n",
    "data.to_csv(\"Scaled_Min_Max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Auction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-a2a96efebe8a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mauction_1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_column\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAuction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdimension\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m# make=tf.feature_column.embedding_column(\"Make\",dimension=32)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model=tf.feature_column.embedding_column(\"Model\",dimension=957)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# submodel=tf.feature_column.embedding_column(\"SubModel\",dimension=826)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# trim=tf.feature_column.embedding_column(\"Trim\",dimension==133)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Auction' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural Nets With OverSampling\n",
    "#Creating Categorical Value -- OneHot Encondoing using HashBucks \n",
    "auction=tf.feature_column.categorical_column_with_hash_bucket(\"Auction\",hash_bucket_size=3)\n",
    "make=tf.feature_column.categorical_column_with_hash_bucket(\"Make\",hash_bucket_size=32)\n",
    "model=tf.feature_column.categorical_column_with_hash_bucket(\"Model\",hash_bucket_size=957)\n",
    "submodel=tf.feature_column.categorical_column_with_hash_bucket(\"SubModel\",hash_bucket_size=826)\n",
    "trim=tf.feature_column.categorical_column_with_hash_bucket(\"Trim\",hash_bucket_size=133)\n",
    "color=tf.feature_column.categorical_column_with_hash_bucket('Color',hash_bucket_size=16)\n",
    "transmission=tf.feature_column.categorical_column_with_hash_bucket('Transmission',hash_bucket_size=3)\n",
    "wheeltype=tf.feature_column.categorical_column_with_hash_bucket(\"WheelType\",hash_bucket_size=3)\n",
    "nationality=tf.feature_column.categorical_column_with_hash_bucket(\"Nationality\",hash_bucket_size=4)\n",
    "size=tf.feature_column.categorical_column_with_hash_bucket('Size',hash_bucket_size=12)\n",
    "topThreeAmericanName=tf.feature_column.categorical_column_with_hash_bucket(\"TopThreeAmericanName\",hash_bucket_size=4)\n",
    "vnst=tf.feature_column.categorical_column_with_hash_bucket(\"VNST\",hash_bucket_size=37)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['WheelTypeID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Continous Feature Columsn for continous variable\n",
    "MMRAcquisitionAuctionAveragePrice=tf.feature_column.numeric_column(\"MMRAcquisitionAuctionAveragePrice\")\n",
    "MMRAcquisitionAuctionCleanPrice=tf.feature_column.numeric_column(\"MMRAcquisitionAuctionCleanPrice\")\n",
    "MMRAcquisitionRetailAveragePrice=tf.feature_column.numeric_column('MMRAcquisitionRetailAveragePrice')\n",
    "MMRAcquisitonRetailCleanPrice=tf.feature_column.numeric_column('MMRAcquisitonRetailCleanPrice')\n",
    "MMRCurrentAuctionAveragePrice=tf.feature_column.numeric_column('MMRCurrentAuctionAveragePrice')\n",
    "MMRCurrentAuctionCleanPrice=tf.feature_column.numeric_column('MMRCurrentAuctionCleanPrice')\n",
    "MMRCurrentAuctionCleanPrice=tf.feature_column.numeric_column('MMRCurrentAuctionCleanPrice')\n",
    "MMRCurrentRetailAveragePrice=tf.feature_column.numeric_column('MMRCurrentRetailAveragePrice')\n",
    "MMRCurrentRetailCleanPrice=tf.feature_column.numeric_column(\"MMRCurrentRetailCleanPrice\")\n",
    "VehBCost=tf.feature_column.numeric_column('VehBCost')\n",
    "WheelTypeID=tf.feature_column.numeric_column('WheelTypeID')\n",
    "VehYear=tf.feature_column.numeric_column('VehYear')\n",
    "VehicleAge=tf.feature_column.numeric_column('VehicleAge')\n",
    "VehOdo=tf.feature_column.numeric_column('VehOdo')\n",
    "BYRNO=tf.feature_column.numeric_column('BYRNO')\n",
    "IsOnlineSale=tf.feature_column.numeric_column('IsOnlineSale')\n",
    "WarrantyCost=tf.feature_column.numeric_column('WarrantyCost')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_col=[auction,make,model,submodel,trim,color,transmission,wheeltype,nationality,size,topThreeAmericanName,vnst,MMRAcquisitionAuctionAveragePrice,MMRAcquisitonRetailCleanPrice,MMRCurrentAuctionAveragePrice,MMRCurrentAuctionCleanPrice,MMRCurrentRetailAveragePrice,MMRCurrentRetailAveragePrice,MMRCurrentRetailCleanPrice,VehBCost,WheelTypeID,IsOnlineSale,BYRNO,VehOdo,VehicleAge,VehYear,WarrantyCost]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feat_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_x,data_y,test_size=0.4,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpmigy44ul\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LENOVO\\\\AppData\\\\Local\\\\Temp\\\\tmpmigy44ul', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001DF59E0A3C8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model=tf.estimator.DNNClassifier(hidden_units=[27,27,27],feature_columns=feat_col,n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=1000,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Duplicate feature column name found for columns: _NumericColumn(key='MMRCurrentRetailAveragePrice', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None) and _NumericColumn(key='MMRCurrentRetailAveragePrice', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None). This usually means that these columns refer to same base feature. Either one must be discarded or a duplicated but renamed item must be inserted in features dict.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-f8c9922af341>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 376\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    377\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1143\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1145\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1147\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1168\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1169\u001b[0m       estimator_spec = self._call_model_fn(\n\u001b[1;32m-> 1170\u001b[1;33m           features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n\u001b[0m\u001b[0;32m   1171\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[0;32m   1172\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[1;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[0;32m   1131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m     \u001b[0mmodel_fn_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done calling model_fn.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[1;34m(features, labels, mode, config)\u001b[0m\n\u001b[0;32m    383\u001b[0m           \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m           \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m           batch_norm=batch_norm)\n\u001b[0m\u001b[0;32m    386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m     super(DNNClassifier, self).__init__(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn\u001b[1;34m(features, labels, mode, head, hidden_units, feature_columns, optimizer, activation_fn, dropout, input_layer_partitioner, config, tpu_estimator_spec, batch_norm)\u001b[0m\n\u001b[0;32m    202\u001b[0m         \u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_layer_partitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m         batch_norm=batch_norm)\n\u001b[1;32m--> 204\u001b[1;33m     \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogit_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtpu_estimator_spec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\estimator\\canned\\dnn.py\u001b[0m in \u001b[0;36mdnn_logit_fn\u001b[1;34m(features, mode)\u001b[0m\n\u001b[0;32m     92\u001b[0m         partitioner=input_layer_partitioner):\n\u001b[0;32m     93\u001b[0m       net = feature_column_lib.input_layer(\n\u001b[1;32m---> 94\u001b[1;33m           features=features, feature_columns=feature_columns)\n\u001b[0m\u001b[0;32m     95\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_hidden_units\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m       with variable_scope.variable_scope(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36minput_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars)\u001b[0m\n\u001b[0;32m    275\u001b[0m   \"\"\"\n\u001b[0;32m    276\u001b[0m   return _internal_input_layer(features, feature_columns, weight_collections,\n\u001b[1;32m--> 277\u001b[1;33m                                trainable, cols_to_vars)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_internal_input_layer\u001b[1;34m(features, feature_columns, weight_collections, trainable, cols_to_vars, scope)\u001b[0m\n\u001b[0;32m    173\u001b[0m   \u001b[1;34m\"\"\"See input_layer. `scope` is a name or variable scope to use.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m   \u001b[0mfeature_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_normalize_feature_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeature_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_DenseColumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\feature_column\\feature_column.py\u001b[0m in \u001b[0;36m_normalize_feature_columns\u001b[1;34m(feature_columns)\u001b[0m\n\u001b[0;32m   2414\u001b[0m                        \u001b[1;34m'duplicated but renamed item must be inserted in '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2415\u001b[0m                        'features dict.'.format(column,\n\u001b[1;32m-> 2416\u001b[1;33m                                                name_to_column[column.name]))\n\u001b[0m\u001b[0;32m   2417\u001b[0m     \u001b[0mname_to_column\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Duplicate feature column name found for columns: _NumericColumn(key='MMRCurrentRetailAveragePrice', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None) and _NumericColumn(key='MMRCurrentRetailAveragePrice', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None). This usually means that these columns refer to same base feature. Either one must be discarded or a duplicated but renamed item must be inserted in features dict."
     ]
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "auction_1=tf.feature_column.embedding_column(auction,dimension=3)\n",
    "make_1=tf.feature_column.embedding_column(make,dimension=32)\n",
    "model_1=tf.feature_column.embedding_column(model,dimension=957)\n",
    "submodel_1=tf.feature_column.embedding_column(submodel,dimension=826)\n",
    "trim_1=tf.feature_column.embedding_column(trim,dimension=133)\n",
    "color_1=tf.feature_column.embedding_column(color,dimension=16)\n",
    "transmission_1=tf.feature_column.embedding_column(transmission,dimension=3)\n",
    "wheeltype_1=tf.feature_column.embedding_column(wheeltype,dimension=3)\n",
    "nationality_1=tf.feature_column.embedding_column(nationality,dimension=4)\n",
    "size_1=tf.feature_column.embedding_column(size,dimension=12)\n",
    "topThreeAmericanName_1=tf.feature_column.embedding_column(topThreeAmericanName,dimension=4)\n",
    "vnst_1=tf.feature_column.embedding_column(vnst,dimension=37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_col=[auction_1,make_1,model_1,submodel_1,trim_1,color_1,transmission_1,wheeltype_1,nationality_1,size_1,topThreeAmericanName_1,vnst_1,MMRAcquisitionAuctionAveragePrice,MMRAcquisitonRetailCleanPrice,MMRCurrentAuctionAveragePrice,MMRCurrentAuctionCleanPrice,MMRCurrentRetailAveragePrice,MMRCurrentRetailCleanPrice,VehBCost,WheelTypeID,IsOnlineSale,BYRNO,VehOdo,VehicleAge,VehYear,WarrantyCost]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpuni9ns8y\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\LENOVO\\\\AppData\\\\Local\\\\Temp\\\\tmpuni9ns8y', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000001DF62E02E48>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "dnn_model = tf.estimator.DNNClassifier(hidden_units=[27,27,27],feature_columns=feat_col,n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpuni9ns8y\\model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpuni9ns8y\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.9074836, step = 1001\n",
      "INFO:tensorflow:global_step/sec: 18.009\n",
      "INFO:tensorflow:loss = 0.41085613, step = 1101 (5.572 sec)\n",
      "INFO:tensorflow:global_step/sec: 45.4806\n",
      "INFO:tensorflow:loss = 0.028997082, step = 1201 (2.202 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.5094\n",
      "INFO:tensorflow:loss = 2.7641401, step = 1301 (2.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 35.7731\n",
      "INFO:tensorflow:loss = 6.626912, step = 1401 (2.799 sec)\n",
      "INFO:tensorflow:global_step/sec: 37.1545\n",
      "INFO:tensorflow:loss = 4.1681476, step = 1501 (2.680 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.1276\n",
      "INFO:tensorflow:loss = 4.85082, step = 1601 (2.150 sec)\n",
      "INFO:tensorflow:global_step/sec: 48.0522\n",
      "INFO:tensorflow:loss = 0.11447828, step = 1701 (2.004 sec)\n",
      "INFO:tensorflow:global_step/sec: 44.0005\n",
      "INFO:tensorflow:loss = 8.644015, step = 1801 (2.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 38.4983\n",
      "INFO:tensorflow:loss = 1.2306268, step = 1901 (2.598 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 2000 into C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpuni9ns8y\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.72314745.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x1df62e02e80>"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.train(input_fn=input_func,steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_input_func = tf.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      y=y_test,\n",
    "      batch_size=10,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-22-04:17:23\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpuni9ns8y\\model.ckpt-2000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-22-04:18:44\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.9046752, accuracy_baseline = 0.9046752, auc = 0.5094091, auc_precision_recall = 0.096050784, average_loss = 0.38172275, global_step = 2000, label/mean = 0.09532481, loss = 3.8169436, precision = 0.0, prediction/mean = 0.05643582, recall = 0.0\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 2000: C:\\Users\\LENOVO\\AppData\\Local\\Temp\\tmpuni9ns8y\\model.ckpt-2000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9046752,\n",
       " 'accuracy_baseline': 0.9046752,\n",
       " 'auc': 0.5094091,\n",
       " 'auc_precision_recall': 0.096050784,\n",
       " 'average_loss': 0.38172275,\n",
       " 'global_step': 2000,\n",
       " 'label/mean': 0.09532481,\n",
       " 'loss': 3.8169436,\n",
       " 'precision': 0.0,\n",
       " 'prediction/mean': 0.05643582,\n",
       " 'recall': 0.0}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnn_model.evaluate(eval_input_func)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
